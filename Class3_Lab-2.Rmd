---
title: "SMML Class 3 Lab"
author: "John Kubale"
date: "9/10/2024"
output: pdf_document
number_sections: yes
fontsize: 12pt
---

```{r setup, include=FALSE, tidy=TRUE}
knitr::opts_chunk$set(echo = TRUE,cache=TRUE, 
                      autodep=TRUE, cache.comments=FALSE,
                      message=FALSE, warning=FALSE)
```

## Import Income2.csv using either the read.csv() or read_csv() function (available on Canvas as well as JWHT Website) and explore the data.

```{r}
inc<-read.csv("C:/Users/jkubale/Dropbox (University of Michigan)/MPSDS 685/data/Income2.csv") #remember to change your filepath!
dim(inc)
names(inc)
summary(inc)
```

## Treat \texttt{Income} as $Y$ and work on the following questions.<br>

### 1. What is the mean of \texttt{Income}?

```{r}
mean(inc$Income)
```

-   $\bar{Y}=$ `r mean(inc$Income)`

### 2. Examine \texttt{Income} in linear regression with no predictor

```{r}
pred_no<-lm(Income~1,inc)
summary(pred_no)
coef(pred_no)
mean(inc$Income)
```

A. What parameter are you estimating in the model? How would you interpret the estimate? How would you put these into a formula?

-   This is an intercept only model which is the parameter you're estimating. You would interpret the estimate of the intercept as the mean of your outcome (in this case income).
-   $Y_i=\bar{Y}+\epsilon_i$

B. What are the residuals and what do they represent? How can you extract the estimates below "Coefficients" when you run summary(no_pred)?

-   The model's residuals can be obtained by `resid(pred_no)`. They represent the difference between the regression line and the observed data points.
-   You can extract the estimates below "Coefficients" using the coef() function.

C. How does results from the regression model compare to the mean in #1?

-   This is the same as $\bar{Y}=$ `r mean(inc$Income)` from #1.

### 3. Examine \texttt{Income} as a fuction of \texttt{Education} in linear regression

```{r}
pred_edu<-lm(Income~Education,inc)
summary(pred_edu)
coef(pred_edu)
coef(pred_edu)[1]
coef(pred_edu)[2]
```

-   To extract a specific coefficient you can reference its row number in the summary table in square brackets following coef().

A. What is this type of linear regression model called? How would you put this into a formula?

-   Linear regression models with 1 predictor are often called simple linear regression models.
-   $Y_i=\beta_0+\beta_1X_i+\epsilon_i$, where $X$ is \texttt{Education}

B. Is the result the same as the one from #2?

-   No. There is an intercept coefficient estimated at `r coef(pred_edu)[1]` and a slope coefficient of \texttt{Education} estimated at `r coef(pred_edu)[2]`.

### 4. Examine \texttt{Income} as a fuction of \texttt{Education} with no intercept in linear regression

```{r}
pred_edu_noint<-lm(Income~Education-1,inc)
summary(pred_edu_noint)
```

A. How would you put this into a formula?

-   $Y_i=\beta_1X_i+\epsilon_i$ where $X$ is \texttt{Education}

B. Is the result the same as the one from #3? Do you have concerns about this modeling approach?

-   No. There is no intercept coefficient, and the slope coefficient of \texttt{Education} estimated at `r coef(pred_edu_noint)[1]`.

-   Yes, only in rare cases should you consider removing the intercept (e.g., you know the intercept passes through the origin).

### 5. Examine \texttt{Income} as a function of \texttt{Seniority} in linear regression

```{r}
pred_sen<-lm(Income~Seniority,inc)
summary(pred_sen)
```

A. How would you put this into a formula?

-   $Y_i=\beta_0+\beta_1X_i+\epsilon_i$ where $X$ is \texttt{Seniority}

B. How does this compare to the result in #3? How would you interpret the coefficient for seniority?

-   Estimated $\beta_0$ and $\beta_1$ are different than those in #3.
-   For every one-unit increase in seniority the mean expected income increases by 0.25.

### 6. Examine \texttt{Income} as a function of \texttt{Education} and \texttt{Seniority} in linear regression

```{r}
pred_both<-lm(Income~Education+Seniority,inc)
summary(pred_both)
```

A. How would you put this into a formula?

-   $Y_i=\beta_0+\beta_1X_{1i}+\beta_2X_{2i}+\epsilon_i$ where $X_1$ is \texttt{Education} $X_2$ is \texttt{Seniority}

B. How does this compare to the result in #3 and #5?

-   There is an intercept coefficient and two slope coefficients associated with \texttt{Education} and \texttt{Seniority}, respectively

C. What do each of the coefficient estimates mean?

-   The intercept coefficient, `r coef(pred_both)[1]`, indicates the level of \texttt{Income} when both \texttt{Education} and \texttt{Seniority} equal 0.
-   The coefficient associated with \texttt{Education}, `r coef(pred_both)[2]`, indicates the change in \texttt{Income} with one unit increase in \texttt{Education} while holding \texttt{Seniority} constant.
-   The coefficient associated with \texttt{Seniority}, `r coef(pred_both)[3]`, indicates the change in \texttt{Income} with one unit increase in \texttt{Seniority} while holdting \texttt{Education}.

### 7. Do #2-6 make sense?

-   Yes, they seem to make sense. The results show that education and seniority are positively associated with income, as one would expect.

### 8. Can you use results from #2-6? Why and why not?

-   The results can potentially be used in many ways. Some examples are to describe the pattern of income as a function of education and seniority, to make policy decisions that will lead to increased income and to predict income of a person with a certain level of education and seniority.
-   The results cannot be used in a causal sense, unless there are established theories to bolster the causal relationship.
